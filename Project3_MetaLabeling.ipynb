{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9600947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XAUUSD 在第2群\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"QuantCommon\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.processing import get_dollar_bars\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clusters = pd.read_csv(\"clusters.csv\", index_col=0)\n",
    "print(f'XAUUSD 在第{clusters.loc[\"XAUUSD_M1\", \"cluster\"]}群')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f254d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AUDUSD...\n",
      "Filtered Dollar Bars Count: 184442\n",
      "Processing EURGBP...\n",
      "Filtered Dollar Bars Count: 182676\n",
      "Processing EURUSD...\n",
      "Filtered Dollar Bars Count: 186054\n",
      "Processing GBPUSD...\n",
      "Filtered Dollar Bars Count: 183075\n",
      "Processing HK50...\n",
      "Filtered Dollar Bars Count: 10739\n",
      "Processing NZDUSD...\n",
      "Filtered Dollar Bars Count: 67499\n",
      "Processing UK100...\n",
      "Filtered Dollar Bars Count: 11067\n",
      "Processing US2000...\n",
      "Filtered Dollar Bars Count: 12016\n",
      "Processing USDCAD...\n",
      "Filtered Dollar Bars Count: 68479\n",
      "Processing XAGUSD...\n",
      "Filtered Dollar Bars Count: 55366\n",
      "Processing XAUUSD...\n",
      "Filtered Dollar Bars Count: 54861\n"
     ]
    }
   ],
   "source": [
    "group = clusters[clusters[\"cluster\"] == clusters.loc[\"XAUUSD_M1\", \"cluster\"]]\n",
    "data = dict({})\n",
    "for i in group.index:\n",
    "    print(f\"Processing {i[:-3]}...\")\n",
    "    filepath = os.path.join(project_root, \"data\", \"FI\", \"M1\",f\"{i}.csv\")\n",
    "    df = pd.read_csv(filepath, parse_dates=True)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = get_dollar_bars(df)\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AUDUSD...\n",
      "Processing EURGBP...\n",
      "Processing EURUSD...\n",
      "Processing GBPUSD...\n",
      "Processing HK50...\n",
      "Processing NZDUSD...\n",
      "Processing UK100...\n",
      "Processing US2000...\n",
      "Processing USDCAD...\n",
      "Processing XAGUSD...\n",
      "Processing XAUUSD...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['intermediate_results/events_data.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metalabeling import add_vertical_barrier, get_events, get_bins\n",
    "from utils.processing import apply_cusum_filter, getDailyVol, cal_weights, compute_talib_features\n",
    "from joblib import load\n",
    "\n",
    "feats_list, labels_list, weights_list, t1_list = [], [], [], []\n",
    "pca_pipe = load(\"models/pipeline_scaler_pca.joblib\")\n",
    "\n",
    "for symbol,df in data.items():\n",
    "    print(f\"Processing {symbol[:-3]}...\")\n",
    "    vol = getDailyVol(df[\"close\"], span0=20)\n",
    "    cusum_events  = apply_cusum_filter(df, volatility=vol).index\n",
    "    vertical_barriers = add_vertical_barrier(cusum_events, df, num_days=2)\n",
    "    pt_sl = [1, 1]\n",
    "    min_ret = 0.003\n",
    "    triple_barrier_events = get_events(close=df[\"close\"],\n",
    "                                                t_events=cusum_events,\n",
    "                                                pt_sl=pt_sl,\n",
    "                                                target=vol,\n",
    "                                                min_ret=min_ret,\n",
    "                                                num_threads=4,\n",
    "                                                vertical_barrier_times=vertical_barriers,\n",
    "                                                side_prediction=None)\n",
    "    labels  = get_bins(triple_barrier_events, df[\"close\"])\n",
    "    weights = cal_weights(triple_barrier_events, df[\"close\"])\n",
    "    feats = compute_talib_features(df,\n",
    "                               periods=[7,28,50,100],\n",
    "                               apply_ffd=True)\n",
    "    \n",
    "    # normalize features\n",
    "    for col in feats.columns:\n",
    "        # 每個 col 分別做 rolling.apply\n",
    "        feats[col] = (\n",
    "            feats[col]\n",
    "            .rolling(window=200, min_periods=1)\n",
    "            .apply(lambda arr: (arr <= arr[-1]).sum() / len(arr), raw=True)\n",
    "        )\n",
    "    idx = feats.index.intersection(labels.index)\n",
    "    feats = feats.loc[idx]\n",
    "    labels = labels.loc[idx][\"bin\"]\n",
    "    weights = weights.loc[idx][\"weight\"]\n",
    "    weights = weights / weights.mean() # normalize weights\n",
    "    t1 = triple_barrier_events.loc[idx][\"t1\"]\n",
    "\n",
    "    # apply PCA\n",
    "    pca_results = pca_pipe.transform(feats)\n",
    "    col = [f\"PCA_{i}\" for i in range(pca_results.shape[1])]\n",
    "    feats = pd.DataFrame(pca_results, columns= col, index=feats.index)\n",
    "\n",
    "    feats_list.append(feats)\n",
    "    labels_list.append(labels.rename(\"label\"))\n",
    "    weights_list.append(weights.rename(\"weight\"))\n",
    "    t1_list.append(t1.rename(\"t1\"))\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# 假設 feats_list, labels_list, weights_list, t1_list 都已經準備好\n",
    "\n",
    "# 1) 直接一次把四個 list 打包存檔\n",
    "dump(\n",
    "    (feats_list, labels_list, weights_list, t1_list),\n",
    "    \"intermediate_results/events_data.joblib\",\n",
    "    compress=3  # 可選壓縮等級，0-9\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cf9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
