{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9600947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"QuantCommon\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.tools import read_file\n",
    "from utils.processing import get_dollar_bars, apply_cusum_filter, getDailyVol\n",
    "import numpy as np\n",
    "\n",
    "# 調整資料路徑，對應 common 裡的資料\n",
    "filepath = os.path.join(project_root, \"data\", \"FI\", \"M1\")\n",
    "file = read_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = clusters[clusters[\"cluster\"] == clusters.loc[\"XAUUSD_M1\", \"cluster\"]]\n",
    "data = dict({})\n",
    "for i in group.index:\n",
    "    print(f\"Processing {i[:-3]}...\")\n",
    "    filepath = os.path.join(project_root, \"data\", \"FI\", \"M1\",f\"{i}.csv\")\n",
    "    df = pd.read_csv(filepath, parse_dates=True)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = get_dollar_bars(df)\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metalabeling import add_vertical_barrier, get_events, get_bins\n",
    "from utils.processing import apply_cusum_filter, getDailyVol, cal_weights, compute_talib_features\n",
    "\n",
    "feats_list, labels_list, weights_list, t1_list = [], [], [], []\n",
    "\n",
    "for symbol,df in data.items():\n",
    "    print(f\"Processing {symbol[:-3]}...\")\n",
    "    vol = getDailyVol(df[\"close\"], span0=20)\n",
    "    cusum_events  = apply_cusum_filter(df, volatility=vol).index\n",
    "    vertical_barriers = add_vertical_barrier(cusum_events, df, num_days=2)\n",
    "    pt_sl = [1, 1]\n",
    "    min_ret = 0.003\n",
    "    triple_barrier_events = get_events(close=df[\"close\"],\n",
    "                                                t_events=cusum_events,\n",
    "                                                pt_sl=pt_sl,\n",
    "                                                target=vol,\n",
    "                                                min_ret=min_ret,\n",
    "                                                num_threads=4,\n",
    "                                                vertical_barrier_times=vertical_barriers,\n",
    "                                                side_prediction=None)\n",
    "    labels  = get_bins(triple_barrier_events, df[\"close\"])\n",
    "    weights = cal_weights(triple_barrier_events, df[\"close\"])\n",
    "    feats = compute_talib_features(df,\n",
    "                               periods=[7,28,50,100],\n",
    "                               apply_ffd=True)\n",
    "    \n",
    "    # normalize features\n",
    "    for col in feats.columns:\n",
    "        # 每個 col 分別做 rolling.apply\n",
    "        feats[col] = (\n",
    "            feats[col]\n",
    "            .rolling(window=200, min_periods=1)\n",
    "            .apply(lambda arr: (arr <= arr[-1]).sum() / len(arr), raw=True)\n",
    "        )\n",
    "    idx = feats.index.intersection(labels.index)\n",
    "    feats = feats.loc[idx]\n",
    "    labels = labels.loc[idx][\"bin\"]\n",
    "    weights = weights.loc[idx][\"weight\"]\n",
    "    weights = weights / weights.mean() # normalize weights\n",
    "    t1 = triple_barrier_events.loc[idx][\"t1\"]\n",
    "\n",
    "    feats_list.append(feats)\n",
    "    labels_list.append(labels.rename(\"bin\"))\n",
    "    weights_list.append(weights.rename(\"weight\"))\n",
    "    t1_list.append(t1.rename(\"t1\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
