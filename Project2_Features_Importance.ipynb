{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5febb32f",
   "metadata": {},
   "source": [
    "### **讀取資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcdaae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XAUUSD 在第2群\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 新的 project_root 指向 common 的上一層\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"QuantCommon\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.tools import read_file\n",
    "from utils.processing import get_dollar_bars\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clusters = pd.read_csv(\"clusters.csv\", index_col=0)\n",
    "print(f'XAUUSD 在第{clusters.loc[\"XAUUSD_M1\", \"cluster\"]}群')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53011ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 184442\n",
      "Filtered Dollar Bars Count: 182676\n",
      "Filtered Dollar Bars Count: 186054\n",
      "Filtered Dollar Bars Count: 183075\n",
      "Filtered Dollar Bars Count: 10739\n",
      "Filtered Dollar Bars Count: 67499\n",
      "Filtered Dollar Bars Count: 11067\n",
      "Filtered Dollar Bars Count: 12016\n",
      "Filtered Dollar Bars Count: 68479\n",
      "Filtered Dollar Bars Count: 55366\n",
      "Filtered Dollar Bars Count: 54861\n"
     ]
    }
   ],
   "source": [
    "group = clusters[clusters[\"cluster\"] == clusters.loc[\"XAUUSD_M1\", \"cluster\"]]\n",
    "\n",
    "data = dict({})\n",
    "for i in group.index:\n",
    "    filepath = os.path.join(project_root, \"data\", \"FI\", \"M1\",f\"{i}.csv\")\n",
    "    df = pd.read_csv(filepath, parse_dates=True)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = get_dollar_bars(df)\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9dfb02",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7320\\2374316763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mvol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDailyVol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspan0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcusum_events\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mapply_cusum_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatility\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvertical_barriers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_vertical_barrier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcusum_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_days\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from utils.metalabeling import add_vertical_barrier, get_events, get_bins\n",
    "from utils.processing import apply_cusum_filter, getDailyVol\n",
    "\n",
    "for _,df in data:\n",
    "    vol = getDailyVol(df[\"close\"], span0=20)\n",
    "    cusum_events  = apply_cusum_filter(df, volatility=vol).index\n",
    "    vertical_barriers = add_vertical_barrier(cusum_events, df, num_days=2)\n",
    "    pt_sl = [1, 1]\n",
    "    min_ret = 0.003\n",
    "    triple_barrier_events = get_events(close=df[\"close\"],\n",
    "                                                t_events=cusum_events,\n",
    "                                                pt_sl=pt_sl,\n",
    "                                                target=vol,\n",
    "                                                min_ret=min_ret,\n",
    "                                                num_threads=4,\n",
    "                                                vertical_barrier_times=vertical_barriers,\n",
    "                                                side_prediction=None)\n",
    "    labels  = get_bins(triple_barrier_events, df[\"close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4243811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "2020-06-22 00:25:00    0.000000\n",
      "2020-06-22 01:23:00   -0.001183\n",
      "2020-06-22 02:19:00    0.000383\n",
      "2020-06-22 02:53:00   -0.000520\n",
      "2020-06-22 03:11:00    0.001200\n",
      "                         ...   \n",
      "2023-12-29 19:53:00   -0.003922\n",
      "2023-12-29 20:25:00   -0.000900\n",
      "2023-12-29 21:00:00   -0.000899\n",
      "2023-12-29 21:38:00   -0.000290\n",
      "2023-12-29 22:10:00   -0.001326\n",
      "Name: close, Length: 54854, dtype: float64\n",
      "CUSUM Bars Count: 13443\n"
     ]
    }
   ],
   "source": [
    "from utils.metalabeling import add_vertical_barrier, get_events, get_bins\n",
    "from utils.processing import apply_cusum_filter, getDailyVol\n",
    "\n",
    "tmp = data[\"XAUUSD_M1\"].copy()\n",
    "\n",
    "vol = getDailyVol(tmp[\"close\"], span0=20)\n",
    "cusum_events  = apply_cusum_filter(tmp, volatility=vol).index\n",
    "vertical_barriers = add_vertical_barrier(cusum_events, tmp, num_days=2)\n",
    "pt_sl = [1, 1]\n",
    "min_ret = 0.003\n",
    "triple_barrier_events = get_events(close=tmp[\"close\"],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=4,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=None)\n",
    "labels  = get_bins(triple_barrier_events, tmp[\"close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703e801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processing import cal_weights\n",
    "\n",
    "weights = cal_weights(triple_barrier_events, tmp[\"close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbafbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processing import compute_talib_features\n",
    "feats = compute_talib_features(tmp,\n",
    "                               periods=[7,14,28,50,100],\n",
    "                               apply_ffd=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f6a29",
   "metadata": {},
   "source": [
    "## Make Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462f8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3448, 208) (3448,) (3448,) (3448,)\n"
     ]
    }
   ],
   "source": [
    "idx = feats.index.intersection(labels.index)\n",
    "feats = feats.loc[idx]\n",
    "labels = labels.loc[idx][\"bin\"]\n",
    "weights =  weights.loc[idx][\"weight\"]\n",
    "t1 = triple_barrier_events.loc[idx][\"t1\"]\n",
    "print(feats.shape, labels.shape, weights.shape, t1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b3aad",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "feats = feats.dropna()\n",
    "class RollingPercentileTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    對每一欄做滑動 percentile 計算，回傳每個時間點 t \n",
    "    欄位值在過去 window 期內的百分位 (0~1)。\n",
    "    \"\"\"\n",
    "    def __init__(self, window: int = 252, min_periods: int = 1):\n",
    "        self.window = window\n",
    "        self.min_periods = min_periods\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # 不需要學任何東西\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # 假設 X 是 DataFrame\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for col in X.columns:\n",
    "            # 每個 col 分別做 rolling.apply\n",
    "            X[col] = (\n",
    "                X[col]\n",
    "                .rolling(window=self.window, min_periods=self.min_periods)\n",
    "                .apply(lambda arr: (arr <= arr[-1]).sum() / len(arr), raw=True)\n",
    "            )\n",
    "        return X.values  # 回傳 numpy array 給後續 scaler\n",
    "\n",
    "# === Pipeline 1: rolling percentile → z-score → PCA ===\n",
    "pipe1 = Pipeline([\n",
    "    (\"roll_pct\", RollingPercentileTransformer(window=252)),\n",
    "    (\"scaler\",  StandardScaler()),\n",
    "    (\"pca\",     PCA(n_components=0.95, whiten=False)),\n",
    "])\n",
    "\n",
    "# === Pipeline 2: z-score → PCA ===\n",
    "pipe2 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\",    PCA(n_components=0.95, whiten=False)),\n",
    "])\n",
    "\n",
    "# === 使用方式 ===\n",
    "# 假設 feats 是一個 DataFrame，columns 就是你的所有技術指標\n",
    "# e.g. feats = compute_talib_features(data)\n",
    "\n",
    "# 1) 第一條流水線\n",
    "X1 = pipe1.fit_transform(feats)  \n",
    "# 2) 第二條流水線\n",
    "X2 = pipe2.fit_transform(feats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4fde4",
   "metadata": {},
   "source": [
    "## MDA MDI SFI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226a295",
   "metadata": {},
   "source": [
    "#### Purged K Fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d762fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PurgedKFold:\n",
    "    def __init__(self, n_splits=3, t1=None, pct_embargo=0.0):\n",
    "        if not isinstance(t1, pd.Series):\n",
    "            raise ValueError(\"t1 must be a pandas Series\")\n",
    "        self.n_splits = n_splits\n",
    "        self.t1 = t1.sort_index()\n",
    "        self.pct_embargo = pct_embargo\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if not X.index.equals(self.t1.index):\n",
    "            raise ValueError(\"X and t1 must have the same index\")\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        # divide indices into contiguous chunks\n",
    "        test_slices = np.array_split(indices, self.n_splits)\n",
    "        mbrg = int(n_samples * self.pct_embargo)\n",
    "\n",
    "        for slice_ in test_slices:\n",
    "            i, j = slice_[0], slice_[-1] + 1\n",
    "            test_idx = indices[i:j]\n",
    "\n",
    "            # start‐time of test block\n",
    "            t0 = self.t1.index[i]\n",
    "            # end‐time of test block\n",
    "            t1_max = self.t1.iloc[test_idx].max()\n",
    "            # find the position just after t1_max\n",
    "            max_t1_pos = self.t1.index.searchsorted(t1_max)\n",
    "\n",
    "            # training before test block\n",
    "            train_before = indices[self.t1.index < t0]\n",
    "            # training after test + embargo\n",
    "            train_after = indices[max_t1_pos + mbrg :]\n",
    "\n",
    "            train_idx = np.concatenate([train_before, train_after])\n",
    "            yield train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4193bf1",
   "metadata": {},
   "source": [
    "#### CVscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "def cv_score(clf,\n",
    "             X,\n",
    "             y,\n",
    "             sample_weight=None,\n",
    "             scoring=\"neg_log_loss\",\n",
    "             t1=None,\n",
    "             cv=3,\n",
    "             pct_embargo=0.01):\n",
    "\n",
    "    if scoring not in [\"neg_log_loss\", \"accuracy\"]:\n",
    "        raise ValueError('scoring must be \"neg_log_loss\" or \"accuracy\"')\n",
    "\n",
    "    pkf = PurgedKFold(n_splits=cv, t1=t1, pct_embargo=pct_embargo)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in pkf.split(X):\n",
    "        # 複製一份新的 model\n",
    "        model = clone(clf)\n",
    "        # fit\n",
    "        if sample_weight is None:\n",
    "            model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        else:\n",
    "            model.fit(X.iloc[train_idx],\n",
    "                      y.iloc[train_idx],\n",
    "                      sample_weight=sample_weight.iloc[train_idx].values)\n",
    "        # predict + score\n",
    "        if scoring == \"neg_log_loss\":\n",
    "            prob = model.predict_proba(X.iloc[test_idx])\n",
    "            sc = -log_loss(y.iloc[test_idx],\n",
    "                           prob,\n",
    "                           sample_weight=(None if sample_weight is None else sample_weight.iloc[test_idx].values),\n",
    "                           labels=model.classes_)\n",
    "        else:\n",
    "            pred = model.predict(X.iloc[test_idx])\n",
    "            sc = accuracy_score(y.iloc[test_idx],\n",
    "                                pred,\n",
    "                                sample_weight=(None if sample_weight is None else sample_weight.iloc[test_idx].values))\n",
    "        scores.append(sc)\n",
    "    return np.array(scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972226d",
   "metadata": {},
   "source": [
    "#### MDA MDI SFI 實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假設你已經有：\n",
    "#   - PurgedKFold 實作  \n",
    "#   - cv_score 函式  \n",
    "# 並且都在 your_module 裡可以 import  \n",
    "\n",
    "\n",
    "# 1) MDI Feature Importance\n",
    "def feat_imp_mdi(fit, feat_names):\n",
    "    \"\"\"\n",
    "    fit: 已訓練好的 tree‐ensemble（RandomForest, ExtraTrees…）\n",
    "    feat_names: list of feature names\n",
    "    return: pd.DataFrame with columns [\"mean\",\"std\"] 純量化後的重要度\n",
    "    \"\"\"\n",
    "    # 從每顆樹蒐集 feature_importances_\n",
    "    df0 = pd.DataFrame(\n",
    "        [tree.feature_importances_ for tree in fit.estimators_],\n",
    "        columns=feat_names\n",
    "    ).replace(0, np.nan)  # 如果 max_features=1，某些 tree 有 0\n",
    "    imp = pd.concat({\n",
    "        \"median\": df0.median(),\n",
    "        \"std\" : df0.std() * df0.shape[0]**-0.5\n",
    "    }, axis=1)\n",
    "    # normalize to sum=1\n",
    "    imp[\"median\"] /= imp[\"median\"].sum()\n",
    "    imp.sort_values(by=\"median\", ascending=False, inplace=True)\n",
    "    return imp\n",
    "\n",
    "\n",
    "# 2) MDA: 支援 X, y, sample_weight, t1 為 np.ndarray\n",
    "def feat_imp_mda(clf,\n",
    "                 X,\n",
    "                 y,\n",
    "                 sample_weight=None,\n",
    "                 t1=None,\n",
    "                 cv: int = 5,\n",
    "                 pct_embargo: float = 0.01,\n",
    "                 scoring: str = \"neg_log_loss\"\n",
    "                ) -> (pd.DataFrame, float):\n",
    "    # --- 1) numpy → pandas ---\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y, index=X.index)\n",
    "    if sample_weight is not None and not isinstance(sample_weight, pd.Series):\n",
    "        sample_weight = pd.Series(sample_weight, index=X.index)\n",
    "    if t1 is not None and not isinstance(t1, pd.Series):\n",
    "        t1 = pd.Series(t1, index=X.index)\n",
    "\n",
    "    feat_names = list(X.columns)\n",
    "\n",
    "    # --- 2) baseline score ---\n",
    "    base_scores = cv_score(clf, X, y,\n",
    "                           sample_weight=sample_weight,\n",
    "                           scoring=scoring,\n",
    "                           t1=t1,\n",
    "                           cv=cv,\n",
    "                           pct_embargo=pct_embargo)\n",
    "    base_mean = base_scores.mean()\n",
    "\n",
    "    # --- 3) 每個 feature permutation, 加進度條 ---\n",
    "    diffs = []\n",
    "    for col in tqdm(feat_names, desc=\"MDA permuting features\"):\n",
    "        Xp = X.copy()\n",
    "        np.random.shuffle(Xp[col].values)\n",
    "        perm_scores = cv_score(clf, Xp, y,\n",
    "                               sample_weight=sample_weight,\n",
    "                               scoring=scoring,\n",
    "                               t1=t1,\n",
    "                               cv=cv,\n",
    "                               pct_embargo=pct_embargo)\n",
    "        diffs.append(base_scores - perm_scores)\n",
    "\n",
    "    diffs = np.vstack(diffs)\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"mean\": diffs.mean(axis=1),\n",
    "        \"std\" : diffs.std(axis=1) * diffs.shape[1]**-0.5\n",
    "    }, index=feat_names)\n",
    "    imp_df.sort_values(by=\"mean\", ascending=False, inplace=True)\n",
    "    return imp_df, base_mean\n",
    "\n",
    "# 3) SFI: 支援 X, y, sample_weight, t1 為 np.ndarray\n",
    "def SFI(feat_names: list,\n",
    "                 clf,\n",
    "                 X: pd.DataFrame,\n",
    "                 y: pd.Series,\n",
    "                 sample_weight=None,\n",
    "                 t1=None,\n",
    "                 cv: int = 5,\n",
    "                 pct_embargo: float = 0.01,\n",
    "                 scoring: str = \"neg_log_loss\"\n",
    "                ) -> pd.DataFrame:\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X, columns=feat_names)\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y, index=X.index)\n",
    "    if sample_weight is not None and not isinstance(sample_weight, pd.Series):\n",
    "        sample_weight = pd.Series(sample_weight, index=X.index)\n",
    "    if t1 is not None and not isinstance(t1, pd.Series):\n",
    "        t1 = pd.Series(t1, index=X.index)\n",
    "\n",
    "    imp = pd.DataFrame(columns=[\"mean\", \"std\"])\n",
    "    for featName in feat_names:\n",
    "        dfo = cv_score(clf, X=X[[featName]],  y = y,\n",
    "                      sample_weight= sample_weight,\n",
    "                      scoring=scoring, t1 = t1, cv = cv)\n",
    "        imp.loc[featName, \"mean\"] = dfo.mean()\n",
    "        imp.loc[featName, \"std\"] = dfo.std() * dfo.shape[0]**-0.5\n",
    "        imp.sort_values(by=\"mean\", ascending=False, inplace=True)\n",
    "    return imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630b0e3",
   "metadata": {},
   "source": [
    "### RF and compute MDI MDA SFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c723464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [f\"PCA_{i}\" for i in range(X2.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "963a12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用CV不用切割資料集\n",
    "X = pd.DataFrame(X2, columns= col, index=feats.index)\n",
    "y = labels.values\n",
    "weights = weights.values\n",
    "# t1 在上面定義好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1a5bfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA_0</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "      <th>PCA_15</th>\n",
       "      <th>PCA_16</th>\n",
       "      <th>PCA_17</th>\n",
       "      <th>PCA_18</th>\n",
       "      <th>PCA_19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-22 16:00:00</th>\n",
       "      <td>-5.799092</td>\n",
       "      <td>-6.667734</td>\n",
       "      <td>2.831685</td>\n",
       "      <td>-4.376821</td>\n",
       "      <td>4.745149</td>\n",
       "      <td>4.974754</td>\n",
       "      <td>2.585366</td>\n",
       "      <td>-0.389366</td>\n",
       "      <td>4.162528</td>\n",
       "      <td>1.293853</td>\n",
       "      <td>1.544921</td>\n",
       "      <td>-1.215628</td>\n",
       "      <td>-2.283115</td>\n",
       "      <td>1.045526</td>\n",
       "      <td>-3.037757</td>\n",
       "      <td>1.378900</td>\n",
       "      <td>1.650350</td>\n",
       "      <td>-2.139362</td>\n",
       "      <td>-0.283402</td>\n",
       "      <td>-0.148872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-28 14:50:00</th>\n",
       "      <td>-12.438673</td>\n",
       "      <td>-5.509063</td>\n",
       "      <td>0.436969</td>\n",
       "      <td>-2.253595</td>\n",
       "      <td>4.779983</td>\n",
       "      <td>-4.238147</td>\n",
       "      <td>-5.008632</td>\n",
       "      <td>-0.920011</td>\n",
       "      <td>4.083533</td>\n",
       "      <td>0.551789</td>\n",
       "      <td>0.355830</td>\n",
       "      <td>0.725524</td>\n",
       "      <td>1.191631</td>\n",
       "      <td>0.931340</td>\n",
       "      <td>1.555752</td>\n",
       "      <td>0.790570</td>\n",
       "      <td>-0.931003</td>\n",
       "      <td>-1.237774</td>\n",
       "      <td>-2.571104</td>\n",
       "      <td>-0.070142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-28 15:58:00</th>\n",
       "      <td>-0.914997</td>\n",
       "      <td>-3.263566</td>\n",
       "      <td>-6.273350</td>\n",
       "      <td>5.583443</td>\n",
       "      <td>2.726280</td>\n",
       "      <td>2.424141</td>\n",
       "      <td>2.093870</td>\n",
       "      <td>1.179466</td>\n",
       "      <td>-0.341848</td>\n",
       "      <td>-0.887487</td>\n",
       "      <td>3.766684</td>\n",
       "      <td>0.869564</td>\n",
       "      <td>1.103646</td>\n",
       "      <td>1.653496</td>\n",
       "      <td>-1.123067</td>\n",
       "      <td>0.720345</td>\n",
       "      <td>0.562026</td>\n",
       "      <td>-1.178783</td>\n",
       "      <td>0.067104</td>\n",
       "      <td>-2.912669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-28 16:15:00</th>\n",
       "      <td>-4.921787</td>\n",
       "      <td>-4.013460</td>\n",
       "      <td>-4.221147</td>\n",
       "      <td>2.292808</td>\n",
       "      <td>3.155357</td>\n",
       "      <td>-1.735619</td>\n",
       "      <td>3.362364</td>\n",
       "      <td>-3.007337</td>\n",
       "      <td>-0.953520</td>\n",
       "      <td>1.139383</td>\n",
       "      <td>3.295104</td>\n",
       "      <td>-0.222116</td>\n",
       "      <td>1.022648</td>\n",
       "      <td>-0.279718</td>\n",
       "      <td>-0.456692</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>-0.455475</td>\n",
       "      <td>-1.646982</td>\n",
       "      <td>-0.944321</td>\n",
       "      <td>-0.659289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-28 16:21:00</th>\n",
       "      <td>-8.490138</td>\n",
       "      <td>-4.423071</td>\n",
       "      <td>-2.284867</td>\n",
       "      <td>0.825572</td>\n",
       "      <td>4.501388</td>\n",
       "      <td>-2.716232</td>\n",
       "      <td>2.577636</td>\n",
       "      <td>-2.354038</td>\n",
       "      <td>0.865607</td>\n",
       "      <td>0.408851</td>\n",
       "      <td>2.383079</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>1.365664</td>\n",
       "      <td>1.509007</td>\n",
       "      <td>-1.289653</td>\n",
       "      <td>0.346439</td>\n",
       "      <td>-0.605571</td>\n",
       "      <td>-1.815647</td>\n",
       "      <td>-1.195692</td>\n",
       "      <td>-0.297338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 16:32:00</th>\n",
       "      <td>-10.078947</td>\n",
       "      <td>10.976820</td>\n",
       "      <td>-2.200420</td>\n",
       "      <td>-5.326469</td>\n",
       "      <td>3.837847</td>\n",
       "      <td>0.166117</td>\n",
       "      <td>-1.960596</td>\n",
       "      <td>-0.426028</td>\n",
       "      <td>2.010870</td>\n",
       "      <td>-1.870346</td>\n",
       "      <td>0.778321</td>\n",
       "      <td>-1.961269</td>\n",
       "      <td>1.455997</td>\n",
       "      <td>1.611769</td>\n",
       "      <td>-0.650180</td>\n",
       "      <td>-2.265725</td>\n",
       "      <td>-0.386517</td>\n",
       "      <td>3.155148</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>0.630826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 17:18:00</th>\n",
       "      <td>-11.826614</td>\n",
       "      <td>11.489787</td>\n",
       "      <td>-0.894275</td>\n",
       "      <td>-3.255975</td>\n",
       "      <td>6.131481</td>\n",
       "      <td>1.406690</td>\n",
       "      <td>-2.766024</td>\n",
       "      <td>-0.444787</td>\n",
       "      <td>1.300437</td>\n",
       "      <td>-1.161436</td>\n",
       "      <td>-0.928581</td>\n",
       "      <td>-2.642621</td>\n",
       "      <td>1.669947</td>\n",
       "      <td>1.000449</td>\n",
       "      <td>-0.558620</td>\n",
       "      <td>-2.406410</td>\n",
       "      <td>-0.332787</td>\n",
       "      <td>3.178175</td>\n",
       "      <td>0.084099</td>\n",
       "      <td>0.079467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23 07:34:00</th>\n",
       "      <td>-6.772874</td>\n",
       "      <td>11.546762</td>\n",
       "      <td>-5.528706</td>\n",
       "      <td>-6.310889</td>\n",
       "      <td>3.496664</td>\n",
       "      <td>-0.622073</td>\n",
       "      <td>2.408875</td>\n",
       "      <td>1.316003</td>\n",
       "      <td>1.649202</td>\n",
       "      <td>0.434992</td>\n",
       "      <td>0.721245</td>\n",
       "      <td>-2.058231</td>\n",
       "      <td>2.431842</td>\n",
       "      <td>0.244633</td>\n",
       "      <td>-1.828676</td>\n",
       "      <td>-1.167709</td>\n",
       "      <td>0.122303</td>\n",
       "      <td>2.939340</td>\n",
       "      <td>0.339328</td>\n",
       "      <td>1.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30 03:22:00</th>\n",
       "      <td>-5.937019</td>\n",
       "      <td>10.048670</td>\n",
       "      <td>-1.800176</td>\n",
       "      <td>-10.201551</td>\n",
       "      <td>3.500005</td>\n",
       "      <td>0.787053</td>\n",
       "      <td>-2.101928</td>\n",
       "      <td>-0.470903</td>\n",
       "      <td>1.261134</td>\n",
       "      <td>1.725928</td>\n",
       "      <td>2.235624</td>\n",
       "      <td>0.501275</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>1.236081</td>\n",
       "      <td>-0.501452</td>\n",
       "      <td>0.882439</td>\n",
       "      <td>0.391568</td>\n",
       "      <td>2.427200</td>\n",
       "      <td>0.284950</td>\n",
       "      <td>0.320626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30 07:32:00</th>\n",
       "      <td>-1.011441</td>\n",
       "      <td>10.950752</td>\n",
       "      <td>-7.491749</td>\n",
       "      <td>-6.394639</td>\n",
       "      <td>1.140040</td>\n",
       "      <td>5.408082</td>\n",
       "      <td>-1.633926</td>\n",
       "      <td>0.626959</td>\n",
       "      <td>-1.054929</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>3.083748</td>\n",
       "      <td>-0.097350</td>\n",
       "      <td>-0.329954</td>\n",
       "      <td>-0.219577</td>\n",
       "      <td>0.462693</td>\n",
       "      <td>1.203752</td>\n",
       "      <td>0.288132</td>\n",
       "      <td>2.913223</td>\n",
       "      <td>-0.352685</td>\n",
       "      <td>0.409964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PCA_0      PCA_1     PCA_2      PCA_3     PCA_4  \\\n",
       "time                                                                       \n",
       "2021-01-22 16:00:00  -5.799092  -6.667734  2.831685  -4.376821  4.745149   \n",
       "2021-01-28 14:50:00 -12.438673  -5.509063  0.436969  -2.253595  4.779983   \n",
       "2021-01-28 15:58:00  -0.914997  -3.263566 -6.273350   5.583443  2.726280   \n",
       "2021-01-28 16:15:00  -4.921787  -4.013460 -4.221147   2.292808  3.155357   \n",
       "2021-01-28 16:21:00  -8.490138  -4.423071 -2.284867   0.825572  4.501388   \n",
       "...                        ...        ...       ...        ...       ...   \n",
       "2024-12-20 16:32:00 -10.078947  10.976820 -2.200420  -5.326469  3.837847   \n",
       "2024-12-20 17:18:00 -11.826614  11.489787 -0.894275  -3.255975  6.131481   \n",
       "2024-12-23 07:34:00  -6.772874  11.546762 -5.528706  -6.310889  3.496664   \n",
       "2024-12-30 03:22:00  -5.937019  10.048670 -1.800176 -10.201551  3.500005   \n",
       "2024-12-30 07:32:00  -1.011441  10.950752 -7.491749  -6.394639  1.140040   \n",
       "\n",
       "                        PCA_5     PCA_6     PCA_7     PCA_8     PCA_9  \\\n",
       "time                                                                    \n",
       "2021-01-22 16:00:00  4.974754  2.585366 -0.389366  4.162528  1.293853   \n",
       "2021-01-28 14:50:00 -4.238147 -5.008632 -0.920011  4.083533  0.551789   \n",
       "2021-01-28 15:58:00  2.424141  2.093870  1.179466 -0.341848 -0.887487   \n",
       "2021-01-28 16:15:00 -1.735619  3.362364 -3.007337 -0.953520  1.139383   \n",
       "2021-01-28 16:21:00 -2.716232  2.577636 -2.354038  0.865607  0.408851   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2024-12-20 16:32:00  0.166117 -1.960596 -0.426028  2.010870 -1.870346   \n",
       "2024-12-20 17:18:00  1.406690 -2.766024 -0.444787  1.300437 -1.161436   \n",
       "2024-12-23 07:34:00 -0.622073  2.408875  1.316003  1.649202  0.434992   \n",
       "2024-12-30 03:22:00  0.787053 -2.101928 -0.470903  1.261134  1.725928   \n",
       "2024-12-30 07:32:00  5.408082 -1.633926  0.626959 -1.054929  0.907542   \n",
       "\n",
       "                       PCA_10    PCA_11    PCA_12    PCA_13    PCA_14  \\\n",
       "time                                                                    \n",
       "2021-01-22 16:00:00  1.544921 -1.215628 -2.283115  1.045526 -3.037757   \n",
       "2021-01-28 14:50:00  0.355830  0.725524  1.191631  0.931340  1.555752   \n",
       "2021-01-28 15:58:00  3.766684  0.869564  1.103646  1.653496 -1.123067   \n",
       "2021-01-28 16:15:00  3.295104 -0.222116  1.022648 -0.279718 -0.456692   \n",
       "2021-01-28 16:21:00  2.383079  0.962312  1.365664  1.509007 -1.289653   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2024-12-20 16:32:00  0.778321 -1.961269  1.455997  1.611769 -0.650180   \n",
       "2024-12-20 17:18:00 -0.928581 -2.642621  1.669947  1.000449 -0.558620   \n",
       "2024-12-23 07:34:00  0.721245 -2.058231  2.431842  0.244633 -1.828676   \n",
       "2024-12-30 03:22:00  2.235624  0.501275  0.568966  1.236081 -0.501452   \n",
       "2024-12-30 07:32:00  3.083748 -0.097350 -0.329954 -0.219577  0.462693   \n",
       "\n",
       "                       PCA_15    PCA_16    PCA_17    PCA_18    PCA_19  \n",
       "time                                                                   \n",
       "2021-01-22 16:00:00  1.378900  1.650350 -2.139362 -0.283402 -0.148872  \n",
       "2021-01-28 14:50:00  0.790570 -0.931003 -1.237774 -2.571104 -0.070142  \n",
       "2021-01-28 15:58:00  0.720345  0.562026 -1.178783  0.067104 -2.912669  \n",
       "2021-01-28 16:15:00  0.641452 -0.455475 -1.646982 -0.944321 -0.659289  \n",
       "2021-01-28 16:21:00  0.346439 -0.605571 -1.815647 -1.195692 -0.297338  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2024-12-20 16:32:00 -2.265725 -0.386517  3.155148  0.285252  0.630826  \n",
       "2024-12-20 17:18:00 -2.406410 -0.332787  3.178175  0.084099  0.079467  \n",
       "2024-12-23 07:34:00 -1.167709  0.122303  2.939340  0.339328  1.005489  \n",
       "2024-12-30 03:22:00  0.882439  0.391568  2.427200  0.284950  0.320626  \n",
       "2024-12-30 07:32:00  1.203752  0.288132  2.913223 -0.352685  0.409964  \n",
       "\n",
       "[4122 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af35c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgU = weights.mean()\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", class_weight=\"balanced\")\n",
    "clf = BaggingClassifier(estimator=clf, n_estimators=1000, max_samples=avgU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1c73d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          median       std\n",
      "PCA_10  0.053839  0.000421\n",
      "PCA_15  0.053119  0.000404\n",
      "PCA_4   0.051702  0.000404\n",
      "PCA_17  0.051656  0.000406\n",
      "PCA_1   0.051380  0.000398\n",
      "PCA_6   0.051320  0.000412\n",
      "PCA_14  0.050161  0.000403\n",
      "PCA_19  0.050110  0.000400\n",
      "PCA_3   0.050083  0.000413\n",
      "PCA_16  0.049945  0.000398\n",
      "PCA_18  0.049815  0.000406\n",
      "PCA_11  0.049576  0.000404\n",
      "PCA_13  0.049454  0.000399\n",
      "PCA_5   0.049263  0.000396\n",
      "PCA_7   0.049117  0.000415\n",
      "PCA_8   0.048678  0.000381\n",
      "PCA_9   0.048476  0.000392\n",
      "PCA_2   0.047525  0.000387\n",
      "PCA_12  0.047445  0.000393\n",
      "PCA_0   0.047337  0.000380\n"
     ]
    }
   ],
   "source": [
    "# 1. MDI\n",
    "clf_fit = clf.fit(X, y, sample_weight=weights)\n",
    "mdi_imp = feat_imp_mdi(clf_fit, col)\n",
    "print(mdi_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dcf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MDA permuting features: 100%|██████████| 20/20 [37:45<00:00, 113.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mean       std\n",
      "PCA_8   0.001491  0.000445\n",
      "PCA_17  0.001370  0.000586\n",
      "PCA_4   0.001166  0.000573\n",
      "PCA_19  0.000805  0.000300\n",
      "PCA_11  0.000736  0.000947\n",
      "PCA_10  0.000730  0.001512\n",
      "PCA_13  0.000630  0.000865\n",
      "PCA_7   0.000580  0.000947\n",
      "PCA_1   0.000416  0.001008\n",
      "PCA_3   0.000381  0.000432\n",
      "PCA_6   0.000376  0.000866\n",
      "PCA_18  0.000369  0.000743\n",
      "PCA_15  0.000005  0.001496\n",
      "PCA_16 -0.000230  0.000801\n",
      "PCA_5  -0.000251  0.000851\n",
      "PCA_9  -0.000368  0.000534\n",
      "PCA_12 -0.000480  0.000863\n",
      "PCA_14 -0.000639  0.000500\n",
      "PCA_2  -0.001096  0.001216\n",
      "PCA_0  -0.001827  0.001479 -0.7009380955929598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. MDA\n",
    "mda_imp, base = feat_imp_mda(\n",
    "    clf, X, y, cv=5,\n",
    "    sample_weight=weights,\n",
    "    t1=t1, pct_embargo=0.01,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "print(mda_imp, base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mean         std\n",
      "PCA_16 -0.836891  0.00624592\n",
      "PCA_0    -0.8486   0.0191458\n",
      "PCA_17 -0.851275   0.0107346\n",
      "PCA_18 -0.851617   0.0136697\n",
      "PCA_5  -0.853323  0.00954717\n",
      "PCA_9  -0.857127   0.0134292\n",
      "PCA_15 -0.861897   0.0043069\n",
      "PCA_10 -0.863975   0.0094395\n",
      "PCA_6  -0.865283   0.0111665\n",
      "PCA_7  -0.865411   0.0114415\n",
      "PCA_2  -0.866265  0.00833982\n",
      "PCA_19 -0.866476  0.00921716\n",
      "PCA_3  -0.872402   0.0115352\n",
      "PCA_4  -0.875083  0.00595834\n",
      "PCA_8  -0.875461  0.00624876\n",
      "PCA_12 -0.882521  0.00575093\n",
      "PCA_11  -0.88269   0.0120514\n",
      "PCA_14  -0.88443   0.0143149\n",
      "PCA_13 -0.897128  0.00950199\n",
      "PCA_1  -0.909431   0.0287834\n"
     ]
    }
   ],
   "source": [
    "# 3. SFI\n",
    "sfi_imp = SFI(X.columns, clf, X, y, scoring=\"neg_log_loss\", sample_weight=weights , cv=5, t1 = t1, pct_embargo=0.01)\n",
    "print(sfi_imp)\n",
    "sfi_imp.to_csv(\"sfi_imp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853043a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
