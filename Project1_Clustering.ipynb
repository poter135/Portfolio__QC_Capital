{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a7ebd6",
   "metadata": {},
   "source": [
    "### **PCA商品分群**\n",
    "- Motivation: 此Project的目的為將性質類似之商品分類，在訓練模型時用同性質商品而非單一商品資料進行訓練，降低訓練時overfitting的機率\n",
    "- 過程如下:\n",
    "    1. 讀取29種商品資料，包含貨幣兌、黃金、原油、指數等商品\n",
    "    2. 將資料轉換為dollar bars(以固定金額為基準的bar，性質較time bars穩定)\n",
    "    3. 計算指標，並對非平穩指標進行Fractional Difference，讓數據平穩化的同時保持記憶性\n",
    "    4. 使用PCA(主成分分析)將資料正交化\n",
    "    5. 使用Kmeans將PCA的結果分群，並將相似的商品歸類在同一群組"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed1ff7",
   "metadata": {},
   "source": [
    "### **讀取資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "讀取並篩選進度: 100%|██████████| 29/29 [02:43<00:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 29 個 DataFrame。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"QuantCommon\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.tools import read_file\n",
    "from utils.processing import get_dollar_bars, apply_cusum_filter, getDailyVol\n",
    "import numpy as np\n",
    "\n",
    "# 調整資料路徑，對應 common 裡的資料\n",
    "filepath = os.path.join(project_root, \"data\", \"FI\", \"M1\")\n",
    "file = read_file(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55f6a3",
   "metadata": {},
   "source": [
    "### **計算指標**\n",
    "- 計算多項指標並對非平穩之指標進行Fractional Difference，讓指標在轉換為平穩序列的同時保持記憶性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29ab7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "# --- 以下 FFD helper functions 跟之前一樣 --- #\n",
    "def get_ffd_weights(d: float, size: int, thresh: float = 1e-5) -> np.ndarray:\n",
    "    w = [1.0]\n",
    "    for k in range(1, size):\n",
    "        w.append(w[-1] * ((-d + k - 1) / k))\n",
    "    w = np.array(w)\n",
    "    M = np.where(np.abs(w) > thresh)[0].max() + 1\n",
    "    return w[:M]\n",
    "\n",
    "def fractional_diff(series: pd.Series, d: float, thresh: float = 1e-5) -> pd.Series:\n",
    "    x = series.values\n",
    "    w = get_ffd_weights(d, len(x), thresh)\n",
    "    if w.size == 1:\n",
    "        return series.copy().rename(series.name)\n",
    "    conv = np.convolve(x, w, mode='valid')\n",
    "    idx = series.index[w.size-1:]\n",
    "    return pd.Series(conv, index=idx, name=series.name)\n",
    "\n",
    "def find_min_d(series: pd.Series, d_grid: np.ndarray) -> float:\n",
    "    for d in d_grid:\n",
    "        ffd = fractional_diff(series, d)\n",
    "        pval = adfuller(ffd.dropna(), maxlag=1, regression='c')[1]\n",
    "        if pval < 0.05:\n",
    "            return d\n",
    "    return d_grid[-1]\n",
    "\n",
    "def safe_log(series: pd.Series, eps: float = 1e-8) -> pd.Series:\n",
    "    return np.log(np.clip(series, a_min=eps, a_max=None))\n",
    "\n",
    "def compute_talib_features(data: pd.DataFrame,\n",
    "                           periods: list = None,\n",
    "                           apply_ffd: bool = True,\n",
    "                           d_vals: np.ndarray = np.linspace(0, 1, 51),\n",
    "                           ffd_thresh: float = 1e-5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    接收含 open, high, low, close, volume 的 DataFrame，\n",
    "    針對 periods 裡每個週期，計算一批 TA-Lib 指標，\n",
    "    並回傳一個新的 DataFrame，裡面是所有這些技術指標特徵。\n",
    "    \"\"\"\n",
    "    if periods is None:\n",
    "        periods = [7, 14, 28, 50, 100]\n",
    "\n",
    "    \n",
    "    high, low, close, volume, log_ret = data['high'], data['low'], data['close'], data['volume'], np.log(data['close']).diff()\n",
    "    # Log Returns\n",
    "    features_df = pd.DataFrame(index=data.index)\n",
    "    features_df['log_ret'] = log_ret\n",
    "    for p in periods:\n",
    "        # —— 波動率類 —— #\n",
    "        features = dict({})\n",
    "        features[f'atr_{p}']      = talib.ATR(high, low, close, timeperiod=p)\n",
    "        upper, mid, lower         = talib.BBANDS(close, timeperiod=p, nbdevup=2, nbdevdn=2)\n",
    "        features[f'bb_width_{p}']  = (upper - lower) / mid\n",
    "        features[f'volatility_{p}'] = log_ret.rolling(window=p, min_periods=p, center=False).std()\n",
    "\n",
    "        # —— 趨勢類 —— #\n",
    "        features[f'sma_{p}']       = talib.SMA(close, timeperiod=p)\n",
    "        features[f'ema_{p}']       = talib.EMA(close, timeperiod=p)\n",
    "        features[f'adx_{p}']       = talib.ADX(high, low, close, timeperiod=p)\n",
    "        features[f'plus_di_{p}']   = talib.PLUS_DI(high, low, close, timeperiod=p)\n",
    "        features[f'minus_di_{p}']  = talib.MINUS_DI(high, low, close, timeperiod=p)\n",
    "        features[f'dx_{p}']        = talib.DX(high, low, close, timeperiod=p)\n",
    "        features[f'adxr_{p}']      = talib.ADXR(high, low, close, timeperiod=p)\n",
    "\n",
    "        # —— 動量／均值回歸類 —— #\n",
    "        features[f'rsi_{p}']       = talib.RSI(close, timeperiod=p)\n",
    "        features[f'roc_{p}']       = talib.ROC(close, timeperiod=p)\n",
    "        features[f'mom_{p}']       = talib.MOM(close, timeperiod=p)\n",
    "        # features[f'autocorr_{p}'] = log_ret.rolling(window=100, min_periods=100, center=False).apply(lambda x: x.autocorr(lag=p), raw=False)\n",
    "        # PPO = (EMA_fast - EMA_slow)/EMA_slow * 100\n",
    "        fast = p\n",
    "        slow = max(2*p, p+1)\n",
    "        features[f'ppo_{p}'], features[f'ppo_signal_{p}'], features[f'ppo_hist_{p}'] = \\\n",
    "            talib.MACDEXT(close,\n",
    "                          fastperiod=fast, fastmatype=0,\n",
    "                          slowperiod=slow, slowmatype=0,\n",
    "                          signalperiod=int(p/2), signalmatype=0)\n",
    "\n",
    "        # KAMA\n",
    "        features[f'kama_{p}']      = talib.KAMA(close, timeperiod=p)\n",
    "\n",
    "        # Williams %R\n",
    "        features[f'willr_{p}']     = talib.WILLR(high, low, close, timeperiod=p)\n",
    "\n",
    "        # Stochastic\n",
    "        slowk, slowd = talib.STOCH(\n",
    "            high, low, close,\n",
    "            fastk_period=p,\n",
    "            slowk_period=max(3, p//3), slowk_matype=0,\n",
    "            slowd_period=max(3, p//3), slowd_matype=0\n",
    "        )\n",
    "        features[f'stoch_k_{p}']   = slowk\n",
    "        features[f'stoch_d_{p}']   = slowd\n",
    "        features_df = pd.concat([features_df, pd.DataFrame(features)], axis=1)\n",
    "\n",
    "    # —— 不需 timeperiod 的指標 —— #\n",
    "    features_df['obv'] = talib.OBV(close, volume)\n",
    "    features_df['adl'] = talib.AD(high, low, close, volume)\n",
    "    features_df['sar'] = talib.SAR(high, low, acceleration=0.02, maximum=0.2)\n",
    "\n",
    "\n",
    "\n",
    "    if apply_ffd:\n",
    "        ffd_dict = {}\n",
    "        for col in features_df.columns:\n",
    "            # 1) 做微分前，自動檢定是否需要平穩化\n",
    "            series = features_df[col].dropna()\n",
    "            # 只對非平穩序列跑 FFD\n",
    "            pval = adfuller(series, maxlag=1, regression='c')[1]\n",
    "            if pval < 0.05:\n",
    "                # 平穩就不動，直接填回原序列\n",
    "                ffd_series = series\n",
    "            else:\n",
    "                # 非平穩就找 d* 並做分數階微分\n",
    "                log_series = safe_log(series)\n",
    "                d_star     = find_min_d(log_series, d_vals)\n",
    "                ffd_series = fractional_diff(log_series, d_star, thresh=ffd_thresh)\n",
    "            # ffd_dict[f'{col}_ffd'] = ffd_series\n",
    "            ffd_dict[f'{col}'] = ffd_series\n",
    "\n",
    "        # 合併並對齊 index\n",
    "        ffd_df = pd.DataFrame(ffd_dict)\n",
    "        features_df = pd.concat([features_df, ffd_df], axis=1)\n",
    "        features_df = features_df.dropna()\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62914089",
   "metadata": {},
   "source": [
    "### **建立PCA Pipeline**\n",
    "- 先把指標用rolling window的方式轉換為precentile\n",
    "- 再把資料標準化後進行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54275107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class RollingPercentileTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    對每一欄做滑動 percentile 計算，回傳每個時間點 t \n",
    "    欄位值在過去 window 期內的百分位 (0~1)。\n",
    "    \"\"\"\n",
    "    def __init__(self, window: int = 252, min_periods: int = 1):\n",
    "        self.window = window\n",
    "        self.min_periods = min_periods\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # 不需要學任何東西\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # 假設 X 是 DataFrame\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for col in X.columns:\n",
    "            # 每個 col 分別做 rolling.apply\n",
    "            X[col] = (\n",
    "                X[col]\n",
    "                .rolling(window=self.window, min_periods=self.min_periods)\n",
    "                .apply(lambda arr: (arr <= arr[-1]).sum() / len(arr), raw=True)\n",
    "            )\n",
    "        return X.values  # 回傳 numpy array 給後續 scaler\n",
    "\n",
    "\n",
    "# === Pipeline : z-score → PCA ===\n",
    "pipe = Pipeline([\n",
    "    ('roll_pct', RollingPercentileTransformer(window=252)),\n",
    "    ('scaler',  StandardScaler()),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cae6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 184439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [03:23<1:35:07, 203.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 11064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/29 [04:01<47:49, 106.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 182677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/29 [07:09<1:02:09, 143.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 188128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [10:46<1:11:54, 172.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 186053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/29 [14:15<1:14:19, 185.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [14:52<51:46, 135.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 10731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7/29 [15:24<37:10, 101.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 189937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [18:50<47:05, 134.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 183083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 9/29 [22:19<52:37, 157.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 11543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [22:53<37:53, 119.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 10738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11/29 [23:17<27:06, 90.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 12/29 [23:54<21:00, 74.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 13/29 [24:31<16:47, 62.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 10645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [24:59<13:07, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 67499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15/29 [28:17<22:29, 96.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16/29 [28:53<16:55, 78.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 10534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 17/29 [29:21<12:36, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 11065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [29:52<09:48, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 11109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 19/29 [30:22<07:41, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 20/29 [30:52<06:13, 41.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 12056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 21/29 [31:24<05:09, 38.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 68478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [34:24<09:26, 80.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 68549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 23/29 [37:46<11:43, 117.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 69163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [41:01<11:42, 140.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 25/29 [41:31<07:09, 107.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 10038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [42:03<04:14, 84.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 55369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 27/29 [45:05<03:48, 114.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 54868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 28/29 [48:10<02:15, 135.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dollar Bars Count: 55850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [51:21<00:00, 106.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 假設有多個商品，每個商品都有自己的 features_df\n",
    "all_pc1_loadings = []\n",
    "\n",
    "for product in tqdm(file):\n",
    "    data = file[product]\n",
    "    data = get_dollar_bars(data)\n",
    "    data = data.iloc[-50000:]\n",
    "    data = compute_talib_features(data,\n",
    "                                 periods=[7,14,28,50,100],\n",
    "                                 apply_ffd=True)\n",
    "    data = data.dropna()\n",
    "    X_scaled = pipe.fit_transform(data)\n",
    "    pca = PCA()\n",
    "    pca.fit(X_scaled)\n",
    "    pc1 = pd.Series(pca.components_[0], index=data.columns)\n",
    "    all_pc1_loadings.append(pc1)\n",
    "\n",
    "loadings_df = pd.DataFrame(np.array(all_pc1_loadings), index=file.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7d16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUDUSD_M1</th>\n",
       "      <td>-0.021945</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.093463</td>\n",
       "      <td>-0.095009</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.074523</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050954</td>\n",
       "      <td>-0.026251</td>\n",
       "      <td>-0.059753</td>\n",
       "      <td>-0.074989</td>\n",
       "      <td>-0.109640</td>\n",
       "      <td>-0.089519</td>\n",
       "      <td>-0.065343</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>-0.015783</td>\n",
       "      <td>-0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS200_M1</th>\n",
       "      <td>-0.021114</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>-0.092561</td>\n",
       "      <td>-0.094327</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.073124</td>\n",
       "      <td>0.074274</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050176</td>\n",
       "      <td>-0.024690</td>\n",
       "      <td>-0.053266</td>\n",
       "      <td>-0.092749</td>\n",
       "      <td>-0.104583</td>\n",
       "      <td>-0.085845</td>\n",
       "      <td>-0.064149</td>\n",
       "      <td>-0.069968</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>-0.076001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURGBP_M1</th>\n",
       "      <td>-0.020929</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.004486</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.096082</td>\n",
       "      <td>-0.097831</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>-0.075930</td>\n",
       "      <td>0.072060</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053374</td>\n",
       "      <td>-0.030474</td>\n",
       "      <td>-0.053062</td>\n",
       "      <td>-0.061482</td>\n",
       "      <td>-0.109551</td>\n",
       "      <td>-0.089493</td>\n",
       "      <td>-0.064544</td>\n",
       "      <td>-0.070102</td>\n",
       "      <td>-0.056523</td>\n",
       "      <td>-0.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURJPY_M1</th>\n",
       "      <td>-0.020743</td>\n",
       "      <td>0.028144</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>-0.091026</td>\n",
       "      <td>-0.092545</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045682</td>\n",
       "      <td>-0.023301</td>\n",
       "      <td>-0.049430</td>\n",
       "      <td>-0.083224</td>\n",
       "      <td>-0.105379</td>\n",
       "      <td>-0.087746</td>\n",
       "      <td>-0.062731</td>\n",
       "      <td>-0.069081</td>\n",
       "      <td>-0.066441</td>\n",
       "      <td>-0.071665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURUSD_M1</th>\n",
       "      <td>-0.019880</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.094499</td>\n",
       "      <td>-0.096131</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>-0.076883</td>\n",
       "      <td>0.074795</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049146</td>\n",
       "      <td>-0.023290</td>\n",
       "      <td>-0.055880</td>\n",
       "      <td>-0.082022</td>\n",
       "      <td>-0.108179</td>\n",
       "      <td>-0.089326</td>\n",
       "      <td>-0.063995</td>\n",
       "      <td>-0.005812</td>\n",
       "      <td>-0.022095</td>\n",
       "      <td>-0.072861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5    \\\n",
       "AUDUSD_M1 -0.021945  0.003266  0.000512  0.000058 -0.093463 -0.095009   \n",
       "AUS200_M1 -0.021114  0.011740  0.004584  0.009096 -0.092561 -0.094327   \n",
       "EURGBP_M1 -0.020929 -0.008563 -0.004486 -0.005588 -0.096082 -0.097831   \n",
       "EURJPY_M1 -0.020743  0.028144  0.015002  0.022638 -0.091026 -0.092545   \n",
       "EURUSD_M1 -0.019880  0.000275  0.000726  0.000372 -0.094499 -0.096131   \n",
       "\n",
       "                6         7         8         9    ...       198       199  \\\n",
       "AUDUSD_M1  0.003220 -0.076904  0.074523  0.001978  ... -0.050954 -0.026251   \n",
       "AUS200_M1  0.001978 -0.073124  0.074274 -0.001083  ... -0.050176 -0.024690   \n",
       "EURGBP_M1  0.007834 -0.075930  0.072060  0.007351  ... -0.053374 -0.030474   \n",
       "EURJPY_M1  0.008642 -0.072224  0.073583  0.004482  ... -0.045682 -0.023301   \n",
       "EURUSD_M1  0.010231 -0.076883  0.074795  0.006930  ... -0.049146 -0.023290   \n",
       "\n",
       "                200       201       202       203       204       205  \\\n",
       "AUDUSD_M1 -0.059753 -0.074989 -0.109640 -0.089519 -0.065343 -0.008174   \n",
       "AUS200_M1 -0.053266 -0.092749 -0.104583 -0.085845 -0.064149 -0.069968   \n",
       "EURGBP_M1 -0.053062 -0.061482 -0.109551 -0.089493 -0.064544 -0.070102   \n",
       "EURJPY_M1 -0.049430 -0.083224 -0.105379 -0.087746 -0.062731 -0.069081   \n",
       "EURUSD_M1 -0.055880 -0.082022 -0.108179 -0.089326 -0.063995 -0.005812   \n",
       "\n",
       "                206       207  \n",
       "AUDUSD_M1 -0.015783 -0.068945  \n",
       "AUS200_M1 -0.071407 -0.076001  \n",
       "EURGBP_M1 -0.056523 -0.067800  \n",
       "EURJPY_M1 -0.066441 -0.071665  \n",
       "EURUSD_M1 -0.022095 -0.072861  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442215a9",
   "metadata": {},
   "source": [
    "### **Kmeans分群**\n",
    "- 將PCA的結果先用silhouette_score找到最適合的群數，再用Kmeans分群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb645679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 208)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def find_best_k_by_silhouette(X, k_range=range(3, 10)):\n",
    "    best_k = k_range[0]\n",
    "    best_score = -1\n",
    "    print(X.shape)\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        score = silhouette_score(X, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    return best_k, best_score\n",
    "best_k, best_score = find_best_k_by_silhouette(loadings_df.values, k_range=range(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff9f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=0)\n",
    "labels = kmeans.fit_predict(loadings_df)\n",
    "\n",
    "loadings_df['cluster'] = labels\n",
    "loadings_df['cluster'].to_csv('clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84154c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
